{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU5yowghWYJU"
      },
      "source": [
        "# Fine-tuning a masked language model (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The notebook is based on the tutorial from [HuggingFace](https://huggingface.co/learn/nlp-course/chapter7/3?fw=pt#fine-tuning-distilbert-with-the-trainer-api)."
      ],
      "metadata": {
        "id": "qCWGBfJKUZbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyD4-rbNl7Ab",
        "outputId": "e628fa78-3bfb-4047-9190-474a829630f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 16 10:23:02 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook. Also we'll use the models with [bert-extractive-summarizer](https://github.com/dmmiller612/bert-extractive-summarizer)."
      ],
      "metadata": {
        "id": "fw6eXQJWUrbv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m3Gi04C2WYJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4786da-6e17-4b8b-f940-b1ada8ebd796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.29.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.13.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.1.99)\n",
            "Requirement already satisfied: protobuf<=3.20.2 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bert-extractive-summarizer in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from bert-extractive-summarizer) (4.29.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from bert-extractive-summarizer) (1.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from bert-extractive-summarizer) (3.5.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (3.1.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (0.14.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (0.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->bert-extractive-summarizer) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->bert-extractive-summarizer) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->bert-extractive-summarizer) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->bert-extractive-summarizer) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy->bert-extractive-summarizer) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->bert-extractive-summarizer) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install accelerate\n",
        "!pip install bert-extractive-summarizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForMaskedLM, \n",
        "    AutoTokenizer, \n",
        "    DataCollatorForLanguageModeling, \n",
        "    default_data_collator,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    AutoConfig, \n",
        "    AutoTokenizer, \n",
        "    AutoModel,\n",
        "    pipeline\n",
        ")\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import collections\n",
        "import numpy as np\n",
        "import math\n",
        "from summarizer import Summarizer"
      ],
      "metadata": {
        "id": "KSEg8R6YYoog"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IM-M1VRSWYJe"
      },
      "outputs": [],
      "source": [
        "model_checkpoint_distilbert = \"distilbert-base-uncased\"\n",
        "model_checkpoint_albert = \"albert-base-v2\"\n",
        "\n",
        "distilbert = AutoModelForMaskedLM.from_pretrained(model_checkpoint_distilbert)\n",
        "albert = AutoModelForMaskedLM.from_pretrained(model_checkpoint_albert)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ALBERT model has 10 times fewer parameters than BERT and 6 times fewer than DistilBERT:"
      ],
      "metadata": {
        "id": "sGgduYnA-3fk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eOLOG5vXWYJe",
        "outputId": "2eda3749-08f2-433a-ec10-7ef49148707b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'>>> DistilBERT number of parameters: 67M'\n",
            "'>>> ALBERT number of parameters: 11M'\n",
            "'>>> BERT number of parameters: 110M'\n"
          ]
        }
      ],
      "source": [
        "distilbert_num_parameters = distilbert.num_parameters() / 1_000_000\n",
        "albert_num_parameters = albert.num_parameters() / 1_000_000\n",
        "\n",
        "print(f\"'>>> DistilBERT number of parameters: {round(distilbert_num_parameters)}M'\")\n",
        "print(f\"'>>> ALBERT number of parameters: {round(albert_num_parameters)}M'\")\n",
        "print(f\"'>>> BERT number of parameters: 110M'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2mINumqGWYJg"
      },
      "outputs": [],
      "source": [
        "text = \"This is a great [MASK].\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = model_checkpoint_albert\n",
        "model = albert"
      ],
      "metadata": {
        "id": "71AFYfIcE4Vf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zpE2PDdFWYJg"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9iDV2VFdWYJh",
        "outputId": "c340363b-9653-4c93-eee8-4d8c9a5c8434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'>>> This is a great idea.'\n",
            "'>>> This is a great recipe.'\n",
            "'>>> This is a great site.'\n",
            "'>>> This is a great tutorial.'\n",
            "'>>> This is a great website.'\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "token_logits = model(**inputs).logits\n",
        "# Find the location of [MASK] and extract its logits\n",
        "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
        "mask_token_logits = token_logits[0, mask_token_index, :]\n",
        "# Pick the [MASK] candidates with the highest logits\n",
        "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
        "\n",
        "for token in top_5_tokens:\n",
        "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tKV7z1qaWYJi",
        "outputId": "de760d4a-54cb-4717-fd13-0596fb41428d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/CShorten___csv/CShorten--ML-ArXiv-Papers-0dcddd7fc76c9211/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117592"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "arxiv_dataset = load_dataset(\"CShorten/ML-ArXiv-Papers\", split=\"train\")\n",
        "len(arxiv_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_length = [len(a) for a in arxiv_dataset['abstract']]\n",
        "average_length = int(sum(average_length) / len(average_length))\n",
        "average_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7G0E9F3DqlO",
        "outputId": "85034f7f-e168-4725-b075-20406c9b69a3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1157"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_dataset = arxiv_dataset.select(range(30000))\n",
        "len(arxiv_dataset)"
      ],
      "metadata": {
        "id": "-IpN3WwvidpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16dad977-fba3-4bcc-c7dd-7e730605b0d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbA7mPjahIYL",
        "outputId": "07ba9b1b-733c-49cb-d658-d08f29a431fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Unnamed: 0.1': 0,\n",
              " 'Unnamed: 0': 0.0,\n",
              " 'title': 'Learning from compressed observations',\n",
              " 'abstract': '  The problem of statistical learning is to construct a predictor of a random\\nvariable $Y$ as a function of a related random variable $X$ on the basis of an\\ni.i.d. training sample from the joint distribution of $(X,Y)$. Allowable\\npredictors are drawn from some specified class, and the goal is to approach\\nasymptotically the performance (expected loss) of the best predictor in the\\nclass. We consider the setting in which one has perfect observation of the\\n$X$-part of the sample, while the $Y$-part has to be communicated at some\\nfinite bit rate. The encoding of the $Y$-values is allowed to depend on the\\n$X$-values. Under suitable regularity conditions on the admissible predictors,\\nthe underlying family of probability distributions and the loss function, we\\ngive an information-theoretic characterization of achievable predictor\\nperformance in terms of conditional distortion-rate functions. The ideas are\\nillustrated on the example of nonparametric regression in Gaussian noise.\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cnp4kgiVWYJj",
        "outputId": "002d21ab-6556-48fe-d45b-77aaa9e6519f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54,
          "referenced_widgets": [
            "71bc9b37cbef43cca754e7def47d1cda",
            "155a8a698f484840be8d2a13abdb9554",
            "dc8b859d3c694fb0a28f2c590f02daa4",
            "271eed64ecd142b8a16a2335cf512358",
            "26733f0f05e143699cd112571f214d4c",
            "7a6d2e84f4d74e5e813beaa5e5eba703",
            "0cd65bce58c6438d9d911eeba8fa4d05",
            "c06fdbbb233e4288a65f1ee881e3e3b3",
            "49d118a888b443e39e23a1645a950d70",
            "a64361cf63a3425eaa1a82d8273d4873",
            "8d55d51f7dd9427982b508f12a29b1f1"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71bc9b37cbef43cca754e7def47d1cda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "def tokenize_function(examples):\n",
        "    result = tokenizer(examples[\"abstract\"])\n",
        "    if tokenizer.is_fast:\n",
        "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
        "    return result\n",
        "\n",
        "\n",
        "# Use batched=True to activate fast multithreading!\n",
        "tokenized_datasets = arxiv_dataset.map(\n",
        "    tokenize_function, batched=True, remove_columns=['Unnamed: 0.1', 'Unnamed: 0', 'title', 'abstract']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sexe7thWjju7",
        "outputId": "b34c5dcd-be41-4ee6-c13c-844f549c6633"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
              "    num_rows: 30000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eGw-59_uWYJk",
        "outputId": "e7d02164-06fe-495d-913f-0146cdf71a28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tokenizer.model_max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "22QgwY1tWYJl"
      },
      "outputs": [],
      "source": [
        "chunk_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aIINhnwjWYJl",
        "outputId": "6c5ae85f-6186-45dd-ef95-d9f5a9d438a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'>>> Abstract 0 length: 230'\n",
            "'>>> Abstract 1 length: 370'\n",
            "'>>> Abstract 2 length: 347'\n"
          ]
        }
      ],
      "source": [
        "# Slicing produces a list of lists for each feature\n",
        "tokenized_samples = tokenized_datasets[:3]\n",
        "\n",
        "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
        "    print(f\"'>>> Abstract {idx} length: {len(sample)}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GJ9jlqnSWYJm",
        "outputId": "59f6535f-8795-4f7d-c406-dc7a7c36c5c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'>>> Concatenated abstract length: 947'\n"
          ]
        }
      ],
      "source": [
        "concatenated_examples = {\n",
        "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
        "}\n",
        "total_length = len(concatenated_examples[\"input_ids\"])\n",
        "print(f\"'>>> Concatenated abstract length: {total_length}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Kzuv-Z9gWYJn",
        "outputId": "1318f558-e274-4702-dc9a-99043d668bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'>>> Chunk length: 128'\n",
            "'>>> Chunk length: 128'\n",
            "'>>> Chunk length: 128'\n",
            "'>>> Chunk length: 128'\n",
            "'>>> Chunk length: 128'\n",
            "'>>> Chunk length: 128'\n",
            "'>>> Chunk length: 128'\n",
            "'>>> Chunk length: 51'\n"
          ]
        }
      ],
      "source": [
        "chunks = {\n",
        "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
        "    for k, t in concatenated_examples.items()\n",
        "}\n",
        "\n",
        "for chunk in chunks[\"input_ids\"]:\n",
        "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1JBn_LEnWYJn"
      },
      "outputs": [],
      "source": [
        "def group_texts(examples):\n",
        "    # Concatenate all texts\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    # Compute length of concatenated texts\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the last chunk if it's smaller than chunk_size\n",
        "    total_length = (total_length // chunk_size) * chunk_size\n",
        "    # Split by chunks of max_len\n",
        "    result = {\n",
        "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    # Create a new labels column\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oQ3oThB4WYJo",
        "outputId": "936bf629-8974-4fc3-a297-7f4e0396a870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "107f9dfdd2624f34adc7becb1f0f58d7",
            "b33d6d5c71cf48d186145c8fe642f10f",
            "4bea752e73dd41f8809d0c6d311375e4",
            "6d6a94a126db4eeaadb9fe7d054eda60",
            "d5ddf9784e8746a8a28450334d57fd3b",
            "ddfd4431423446b2af80b0b886fc96ce",
            "9541335d334a44d2bab0a031cb8d4169",
            "6311a906ed89434b97c5dff107e9e300",
            "3a56149e1dd441d9894281b52f2bf9cf",
            "5fdc620a40de4af4831451ae6abf0937",
            "80568598726148ae9adfbf432d115c51"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/30000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "107f9dfdd2624f34adc7becb1f0f58d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
              "    num_rows: 50903\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
        "lm_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qFS_qwDkWYJo",
        "outputId": "5fa717d0-3b5d-4770-f9d6-37988c4cf2d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'communicated at some finite bit rate. the encoding of the $y$-values is allowed to depend on the $x$-values. under suitable regularity conditions on the admissible predictors, the underlying family of probability distributions and the loss function, we give an information-theoretic characterization of achievable predictor performance in terms of conditional distortion-rate functions. the ideas are illustrated on the example of nonparametric regression in gaussian noise.[SEP][CLS] in a sensor network, in practice, the communication among sensors is subject to:(1) errors or failures at random'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "tokenizer.decode(lm_datasets[1][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "x8FcTLbeWYJp"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "X39cztntWYJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5833fcfb-0979-453f-8112-3d5cf78c551d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a AlbertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'>>> [CLS] the problem of statistical learning is to construct a predictor of[MASK] random variable[MASK]y$ as a function of a related[MASK] variable $x[MASK] on the basis of an i.i.[MASK]. training[MASK] from the joint distribution of $(x,y[MASK]$. allowable[MASK]ors are drawn from some specified class, and the goal is to approach asymptotically[MASK] performance (expected loss) of the best predictor in the class[MASK] we consider the setting in which one[MASK] resin observation of the[MASK]x$-[MASK][MASK] the sample, while the $y$-part has to be'\n",
            "\n",
            "'>>> communicated at some[MASK] bit rate[MASK][MASK] encoding of the $y$-values is allowed to depend[MASK] the[MASK]x$-values. under[MASK] regularity conditions on[MASK] admissible predictors, the[MASK] family[MASK] probability distribution striker and[MASK] loss function, weern an information-theoretic[MASK]characterization of a[MASK]evable predictor performance in terms of conditional distortion-rate functions. the ideas are illustrated on the example of nonparametric regression in gaussian noise.[SEP][CLS] in a sensor network, in practice, dictated communication among sensors is subject to:(1)[MASK] or failures[MASK] random'\n"
          ]
        }
      ],
      "source": [
        "samples = [lm_datasets[i] for i in range(2)]\n",
        "for sample in samples:\n",
        "    _ = sample.pop(\"word_ids\")\n",
        "\n",
        "for chunk in data_collator(samples)[\"input_ids\"]:\n",
        "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bRpMnBw8WYJq"
      },
      "outputs": [],
      "source": [
        "wwm_probability = 0.2\n",
        "\n",
        "\n",
        "def whole_word_masking_data_collator(features):\n",
        "    for feature in features:\n",
        "        word_ids = feature.pop(\"word_ids\")\n",
        "\n",
        "        # Create a map between words and corresponding token indices\n",
        "        mapping = collections.defaultdict(list)\n",
        "        current_word_index = -1\n",
        "        current_word = None\n",
        "        for idx, word_id in enumerate(word_ids):\n",
        "            if word_id is not None:\n",
        "                if word_id != current_word:\n",
        "                    current_word = word_id\n",
        "                    current_word_index += 1\n",
        "                mapping[current_word_index].append(idx)\n",
        "\n",
        "        # Randomly mask words\n",
        "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
        "        input_ids = feature[\"input_ids\"]\n",
        "        labels = feature[\"labels\"]\n",
        "        new_labels = [-100] * len(labels)\n",
        "        for word_id in np.where(mask)[0]:\n",
        "            word_id = word_id.item()\n",
        "            for idx in mapping[word_id]:\n",
        "                new_labels[idx] = labels[idx]\n",
        "                input_ids[idx] = tokenizer.mask_token_id\n",
        "        feature[\"labels\"] = new_labels\n",
        "\n",
        "    return default_data_collator(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lXwVNCHRWYJq",
        "outputId": "3bb8fd4f-0848-4659-c9f7-8b3e41254210",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'>>> [CLS] the[MASK] of statistical learning is to construct[MASK] predictor of a random variable[MASK][MASK][MASK] as a function of a related random[MASK] $x$ on[MASK][MASK] of[MASK] i.i.d. training sample[MASK] the joint distribution[MASK] $(x,y)$. allowable predictors are drawn from some specified[MASK][MASK][MASK] the goal is to[MASK][MASK][MASK][MASK][MASK][MASK][MASK] performance (expected loss) of the[MASK] predictor in the class. we consider[MASK] setting in which one has perfect observation of the $x$-part of[MASK] sample, while the $y$-part[MASK][MASK] be'\n",
            "\n",
            "'>>> communicated at some finite bit rate. the encoding[MASK] the $y$-values is[MASK] to depend on the $x$-values.[MASK] suitable regularity conditions[MASK] the admissible predictors, the underlying family of probability distributions and the[MASK] function, we[MASK][MASK] information-theoretic characterization of achievable predictor performance in terms of conditional distortion-rate[MASK][MASK] the ideas[MASK] illustrated[MASK] the example[MASK] nonparametric regression in gaussian noise.[SEP][CLS] in a sensor network, in practice,[MASK] communication among sensors is subject to:(1) errors[MASK] failures[MASK] random'\n"
          ]
        }
      ],
      "source": [
        "samples = [lm_datasets[i] for i in range(2)]\n",
        "batch = whole_word_masking_data_collator(samples)\n",
        "\n",
        "for chunk in batch[\"input_ids\"]:\n",
        "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9XuzuhEZWYJr",
        "outputId": "35f7031d-dbae-4d6b-91b1-1a84218905ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "train_size = 10_000\n",
        "test_size = int(0.1 * train_size)\n",
        "\n",
        "downsampled_dataset = lm_datasets.train_test_split(\n",
        "    train_size=train_size, test_size=test_size, seed=42\n",
        ")\n",
        "downsampled_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-Oe4t-VnWYJs"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "# Show the training loss with every epoch\n",
        "logging_steps = len(downsampled_dataset[\"train\"]) // batch_size\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"{model_name}-finetuned-arxiv\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    # push_to_hub=True,\n",
        "    fp16=True,\n",
        "    logging_steps=logging_steps,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Dmyk3bm3WYJs"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=downsampled_dataset[\"train\"],\n",
        "    eval_dataset=downsampled_dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mi0v6VIGWYJt",
        "outputId": "183212a8-090d-4f9a-f0c4-b6c02c558818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Perplexity: 149837.82\n"
          ]
        }
      ],
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "HLxi41odWYJu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "82c35952-a7c1-4430-e795-a1dc0a5c704c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [471/471 04:56, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.738000</td>\n",
              "      <td>2.664310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.549700</td>\n",
              "      <td>2.502258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.445800</td>\n",
              "      <td>2.482439</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 01:40]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=471, training_loss=2.9081290846417662, metrics={'train_runtime': 296.7657, 'train_samples_per_second': 101.09, 'train_steps_per_second': 1.587, 'total_flos': 168558059520000.0, 'train_loss': 2.9081290846417662, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "REJcHsITWYJv",
        "outputId": "4876292b-be49-4217-c35b-577c44aaafe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Perplexity: 11.34\n"
          ]
        }
      ],
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_path = 'distilbert_arxiv_finetuned'\n",
        "trainer.save_model(saved_model_path)"
      ],
      "metadata": {
        "id": "jpI19GuvlhM8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ = AutoModelForMaskedLM.from_pretrained(saved_model_path)\n",
        "tokenizer_ = AutoTokenizer.from_pretrained(saved_model_path)"
      ],
      "metadata": {
        "id": "NPyeOy75i2k9"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = arxiv_dataset[55]['abstract']"
      ],
      "metadata": {
        "id": "MMmOTjVmo5Yw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmn4GjGHpHet",
        "outputId": "9d0b58e8-641c-4681-c3b3-d800d2299c62"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1162"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model, model config and tokenizer via Transformers\n",
        "custom_config = AutoConfig.from_pretrained(saved_model_path)\n",
        "custom_config.output_hidden_states=True\n",
        "custom_tokenizer = AutoTokenizer.from_pretrained(saved_model_path)\n",
        "custom_model = AutoModel.from_pretrained(saved_model_path, \n",
        "                                         config=custom_config)\n",
        "\n",
        "\n",
        "model = Summarizer(custom_model=custom_model, custom_tokenizer=custom_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69mWPJb8TfgN",
        "outputId": "a4cfd5a5-302b-4481-f4bb-5aea9a836eb3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert_arxiv_finetuned were not used when initializing AlbertModel: ['predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.dense.bias', 'predictions.bias', 'predictions.dense.weight', 'predictions.decoder.bias']\n",
            "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertModel were not initialized from the model checkpoint at distilbert_arxiv_finetuned and are newly initialized: ['albert.pooler.bias', 'albert.pooler.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(doc, ratio=0.2, return_as_list=True)"
      ],
      "metadata": {
        "id": "F7BmnBnDXMhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "345b615b-d7cf-49e6-8a35-01b38858ebb7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "V6JWub6HVtZM",
        "outputId": "b4356636-cac3-4530-822b-8d8756ad05bf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  Higher-order tensor decompositions are analogous to the familiar Singular\\nValue Decomposition (SVD), but they transcend the limitations of matrices\\n(second-order tensors). SVD is a powerful tool that has achieved impressive\\nresults in information retrieval, collaborative filtering, computational\\nlinguistics, computational vision, and other fields. However, SVD is limited to\\ntwo-dimensional arrays of data (two modes), and many potential applications\\nhave three or more modes, which require higher-order tensor decompositions.\\nThis paper evaluates four algorithms for higher-order tensor decomposition:\\nHigher-Order Singular Value Decomposition (HO-SVD), Higher-Order Orthogonal\\nIteration (HOOI), Slice Projection (SP), and Multislice Projection (MP). We\\nmeasure the time (elapsed run time), space (RAM and disk space requirements),\\nand fit (tensor reconstruction accuracy) of the four algorithms, under a\\nvariety of conditions. We find that standard implementations of HO-SVD and HOOI\\ndo not scale up to larger tensors, due to increasing RAM requirements. We\\nrecommend HOOI for tensors that are small enough for the available RAM and MP\\nfor larger tensors.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGiqw2stT1Zs",
        "outputId": "3bbf4f23-1200-472f-ee99-6bc36474acda"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Higher-order tensor decompositions are analogous to the familiar Singular\\nValue Decomposition (SVD), but they transcend the limitations of matrices\\n(second-order tensors).',\n",
              " 'We find that standard implementations of HO-SVD and HOOI\\ndo not scale up to larger tensors, due to increasing RAM requirements.']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f\"The summary is less than the input by {round(100 - 100*len(' '.join(output))/len(doc))}%\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3RFIPqpcVO7b",
        "outputId": "09e39e68-532d-4228-dd75-a56986ccf4eb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The summary is less than the input by 74%'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pPFUy2iGWAku"
      },
      "execution_count": 42,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "71bc9b37cbef43cca754e7def47d1cda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_155a8a698f484840be8d2a13abdb9554",
              "IPY_MODEL_dc8b859d3c694fb0a28f2c590f02daa4",
              "IPY_MODEL_271eed64ecd142b8a16a2335cf512358"
            ],
            "layout": "IPY_MODEL_26733f0f05e143699cd112571f214d4c"
          }
        },
        "155a8a698f484840be8d2a13abdb9554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a6d2e84f4d74e5e813beaa5e5eba703",
            "placeholder": "",
            "style": "IPY_MODEL_0cd65bce58c6438d9d911eeba8fa4d05",
            "value": "Map: 100%"
          }
        },
        "dc8b859d3c694fb0a28f2c590f02daa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c06fdbbb233e4288a65f1ee881e3e3b3",
            "max": 30000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49d118a888b443e39e23a1645a950d70",
            "value": 30000
          }
        },
        "271eed64ecd142b8a16a2335cf512358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a64361cf63a3425eaa1a82d8273d4873",
            "placeholder": "",
            "style": "IPY_MODEL_8d55d51f7dd9427982b508f12a29b1f1",
            "value": " 30000/30000 [00:47&lt;00:00, 631.82 examples/s]"
          }
        },
        "26733f0f05e143699cd112571f214d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "7a6d2e84f4d74e5e813beaa5e5eba703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cd65bce58c6438d9d911eeba8fa4d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c06fdbbb233e4288a65f1ee881e3e3b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49d118a888b443e39e23a1645a950d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a64361cf63a3425eaa1a82d8273d4873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d55d51f7dd9427982b508f12a29b1f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "107f9dfdd2624f34adc7becb1f0f58d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b33d6d5c71cf48d186145c8fe642f10f",
              "IPY_MODEL_4bea752e73dd41f8809d0c6d311375e4",
              "IPY_MODEL_6d6a94a126db4eeaadb9fe7d054eda60"
            ],
            "layout": "IPY_MODEL_d5ddf9784e8746a8a28450334d57fd3b"
          }
        },
        "b33d6d5c71cf48d186145c8fe642f10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddfd4431423446b2af80b0b886fc96ce",
            "placeholder": "",
            "style": "IPY_MODEL_9541335d334a44d2bab0a031cb8d4169",
            "value": "Map: 100%"
          }
        },
        "4bea752e73dd41f8809d0c6d311375e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6311a906ed89434b97c5dff107e9e300",
            "max": 30000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a56149e1dd441d9894281b52f2bf9cf",
            "value": 30000
          }
        },
        "6d6a94a126db4eeaadb9fe7d054eda60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fdc620a40de4af4831451ae6abf0937",
            "placeholder": "",
            "style": "IPY_MODEL_80568598726148ae9adfbf432d115c51",
            "value": " 30000/30000 [00:56&lt;00:00, 507.29 examples/s]"
          }
        },
        "d5ddf9784e8746a8a28450334d57fd3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ddfd4431423446b2af80b0b886fc96ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9541335d334a44d2bab0a031cb8d4169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6311a906ed89434b97c5dff107e9e300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a56149e1dd441d9894281b52f2bf9cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fdc620a40de4af4831451ae6abf0937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80568598726148ae9adfbf432d115c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}